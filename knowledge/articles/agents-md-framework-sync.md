---
title: Agents.md Outperforms Skills in Agent Evals
type: article
date_added: 2026-01-28
source: https://vercel.com/blog/agents-md-outperforms-skills-in-our-agent-evals
author: Vercel
via: @vercel
tags:
  - ai-agents
  - framework-sync
  - next-js
  - claude-md
  - evaluation
---

# Agents.md Outperforms Skills in Agent Evals

## Overview

Vercel conducted evaluations of different approaches for keeping AI agents in sync with exact framework versions in projects. They tested multiple strategies including Skills and CLAUDE.md approaches.

## Key Finding

One approach scored 100% on Vercel's Next.js agent evaluations: **Agents.md**

## Context

The challenge: keeping AI agents synchronized with the precise framework versions and configurations in a project so they can reason accurately and provide relevant assistance.

## Approaches Evaluated

- **Skills**: Traditional agent skill definitions
- **CLAUDE.md**: Framework configuration via markdown documentation
- **Agents.md**: Vercel's approach (100% evaluation success)

## Implications

The 100% evaluation success suggests that Agents.md is a superior approach for:
- Maintaining agent accuracy across framework versions
- Keeping agents in sync with project-specific configurations
- Providing reliable agent assistance for Next.js projects

## Relevance

This research is particularly relevant for developers using Claude AI agents with Next.js applications, suggesting the Agents.md format is the most effective way to ground agents in framework-specific knowledge.
