---
title: "Code Factory: How to setup your repo so your agent can auto write and review 100% of your code"
type: x-article
date_added: 2026-02-18
source: "https://x.com/i/article/2023001790258573312"
author: "ryancarson"
tags: [ai-agents, ci-cd, code-review, automation, devops, repo-setup]
via: "Twitter bookmark from @ryancarson"
---

Ryan Carson's framework for autonomous agent code review establishes a control-plane pattern that enforces deterministic checks before merge: agents write code, policy gates validate risk, and review agents approve with auditable evidence. This approach replaces traditional ad-hoc review with machine-verifiable contracts that scale across concurrent agent workflows.

## Key Takeaways

- Machine-readable risk contracts eliminate ambiguity about which code paths require what checks and evidence
- Preflight gates must run before expensive CI to avoid wasting compute on already-blocked PRs
- Current-head SHA discipline prevents merging PRs using stale "clean" evidence from older commits
- Canonical rerun writers with deduplication eliminate duplicate bot comments and race conditions
- Remediation agents can fix findings in-branch and trigger deterministic reruns, reducing loop time
- Browser evidence manifests (not just screenshots) create first-class proof for UI changes
- Incident-to-harness loops convert production regressions into permanent test coverage and SLA tracking

## Full Content

Code Factory: How to setup your repo so your agent can auto write and review 100% of your code

## The goal

You want one loop:

1. The coding agent writes code

2. The repo enforces risk-aware checks before merge

3. A code review agent validates the PR

4. Evidence (tests + browser + review) is machine-verifiable

5. Findings turn into repeatable harness cases

The specific review agent can be @greptile, @coderabbitai, CodeQL + policy logic, custom LLM review, or another service. The control-plane pattern stays the same.

I took inspiration from this helpful blog post by @_lopopolo

[Embedded Tweet: https://x.com/i/status/2022716244361683236]

---

## The high-level flow

## 1) Keep one machine-readable contract

Your contract should define:

- risk tiers by path

- required checks by tier

- docs drift rules for control-plane changes

- evidence requirements for UI/critical flows

```json
{
  "version": "1",
  "riskTierRules": {
    "high": [
      "app/api/legal-chat/**",
      "lib/tools/**",
      "db/schema.ts"
    ],
    "low": ["**"]
  },
  "mergePolicy": {
    "high": {
      "requiredChecks": [
        "risk-policy-gate",
        "harness-smoke",
        "Browser Evidence",
        "CI Pipeline"
      ]
    },
    "low": {
      "requiredChecks": ["risk-policy-gate", "CI Pipeline"]
    }
  }
}
```

Why it matters: it removes ambiguity and prevents silent drift between scripts, workflow files, and policy docs.

---

## 2) Gate preflight before expensive CI

A reliable pattern is:

1. run `risk-policy-gate` first

2. verify deterministic policy + review-agent state

3. only then start `test/build/security` fanout jobs

This avoids wasting CI minutes on PR heads that are already blocked by policy or unresolved review findings.

```typescript
const requiredChecks = computeRequiredChecks(changedFiles, riskTier);
await assertDocsDriftRules(changedFiles);
await assertRequiredChecksSuccessful(requiredChecks);

if (needsCodeReviewAgent(changedFiles, riskTier)) {
  await waitForCodeReviewCompletion({ headSha, timeoutMinutes: 20 });
  await assertNoActionableFindingsForHead(headSha);
}
```

---

## 3) Enforce current-head SHA discipline

This was the biggest practical lesson from real PR loops.

Treat review state as valid only when it matches the current PR head commit:

- wait for the review check run on `headSha`

- ignore stale summary comments tied to older SHAs

- fail if the latest review run is non-success or times out

- require reruns after each synchronize/push

- clear stale gate failures by rerunning policy gate on the same head

If you skip this, you can merge a PR using stale “clean” evidence.

---

## 4) Use a single rerun-comment writer with SHA dedupe

When multiple workflows can request reruns, duplicate bot comments and race conditions appear.

Use exactly one workflow as canonical rerun requester and dedupe by marker + `sha:<head>`.

```typescript
const marker = '<!-- review-agent-auto-rerun -->';
const trigger = `sha:${headSha}`;
const alreadyRequested = comments.some((c) =>
  c.body.includes(marker) && c.body.includes(trigger),
);

if (!alreadyRequested) {
  postComment(`${marker}\n@review-agent please re-review\n${trigger}`);
}
```

---

## 5) Add an automated remediation loop (optional, high leverage)

If review findings are actionable, trigger a coding agent to:

1. read review context

2. patch code

3. run focused local validation

4. push fix commit to the same PR branch

Then let PR synchronize trigger the normal rerun path. Keep this deterministic:

- pin model + effort for reproducibility

- skip stale comments not matching current head

- never bypass policy gates

---

## 6) Auto-resolve bot-only threads only after clean rerun

A useful quality-of-life step:

- after a clean current-head rerun

- auto-resolve unresolved threads where all comments are from the review bot

- never auto-resolve human-participated threads

Then rerun policy gate so required-conversation-resolution reflects the new state.

---

## 7) Keep browser evidence as first-class proof

For UI or user-flow changes, require evidence manifests and assertions in CI (not just screenshots in PR text):

- required flows exist

- expected entrypoint was used

- expected account identity is present for logged-in flows

- artifacts are fresh and valid

```bash
npm run harness:ui:capture-browser-evidence
npm run harness:ui:verify-browser-evidence
```

---

## 8) Preserve incident memory with a harness-gap loop

```plaintext
production regression -> harness gap issue -> case added -> SLA tracked
```

This keeps fixes from becoming one-off patches and grows long-term coverage.

---

## 9) What we learned running this in PRs

The most important lessons were:

1. Deterministic ordering matters: preflight gate must complete before CI fanout.

2. Current-head SHA matching is non-negotiable.

3. Review rerun requests need one canonical writer.

4. Review summary parsing should treat vulnerability language and weak-confidence summaries as actionable.

5. Auto-resolving bot-only threads reduces friction, but only after clean current-head evidence.

6. A remediation agent can shorten loop time significantly if guardrails stay strict.

---

## 10) General pattern vs. one implementation

General pattern terms:

- `code review agent`

- `remediation agent`

- `risk policy gate`

One concrete implementation (ours):

- code review agent: Greptile

- remediation agent: Codex Action

- canonical rerun workflow: `greptile-rerun.yml`

- stale-thread cleanup workflow: `greptile-auto-resolve-threads.yml`

- preflight policy workflow: `risk-policy-gate.yml`

If you use a different reviewer, keep the same control-plane semantics and swap integration points.

---

## Useful command set

```bash
npm run typecheck
npm test
npm run build:ci
npm run harness:legal-chat:smoke
npm run harness:ui:pre-pr
npm run harness:risk-tier
npm run harness:weekly-metrics
```

---

## Final pattern to copy

1. Put risk + merge policy into one contract.

2. Enforce preflight gate before expensive CI.

3. Require clean code-review-agent state for current head SHA.

4. If findings exist, remediate in-branch and rerun deterministically.

5. Auto-resolve only bot-only stale threads after clean rerun.

6. Require browser evidence for UI/flow changes.

7. Convert incidents into harness cases and track loop SLOs.

That gives you a repo where agents can implement, validate, and be reviewed with deterministic, auditable standards.

## Links

- [Article](https://x.com/i/article/2023001790258573312)
- [Original Tweet](https://x.com/ryancarson/status/2023452909883609111)
